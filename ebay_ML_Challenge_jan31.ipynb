{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Initiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialData = pd.read_csv('mlchallenge_set_2021.csv', names=[\"Category\", \"Primary_Image\", \"All_Image\", \"Attributes\",\"Index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialData1=initialData[['Category','Primary_Image','All_Image','Index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialData2=pd.DataFrame(initialData['Attributes'],dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialData2['Attributes'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AttributesParsing(string):\n",
    "    string=string[1:]\n",
    "    string=string[:-1]\n",
    "    string=string.upper()\n",
    "    string_list=re.split('[:]',string)\n",
    "    \n",
    "    n=len(string_list)\n",
    "    string_list2=[]\n",
    "    for i in range(n-1):\n",
    "        list2=re.split('[,]',string_list[i])\n",
    "        string_list2.append(list2)\n",
    "        \n",
    "    last_term_array=[string_list[n-1]]    \n",
    "    string_list2.append(last_term_array)\n",
    "    \n",
    "    attributes_dict={}\n",
    "    k1=0;k2=0\n",
    "    \n",
    "    for i in range(n-2):\n",
    "        k1=len(string_list2[i])\n",
    "        k2=len(string_list2[i+1])\n",
    "        attributes_dict[string_list2[i][k1-1]]=','.join(string_list2[i+1][0:k2-1])\n",
    "    \n",
    "    attributes_dict[string_list2[n-2][k2-1]]=','.join(last_term_array)\n",
    "    \n",
    "    \n",
    "    return attributes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialData2['Attributes'][50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttributesParsing(initialData2['Attributes'][50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TotalObs=len(initialData)\n",
    "TotalObs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Attributes_Parsed=[None]*TotalObs\n",
    "\n",
    "for i in range(TotalObs):\n",
    "     Attributes_Parsed[i]=AttributesParsing(initialData2['Attributes'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Attributes_Parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialData2['Attributes_Parsed']=Attributes_Parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialData2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialData1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialData['Attributes_Parsed']=initialData2['Attributes_Parsed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_list=[]\n",
    "for i in range(TotalObs):\n",
    "    key_list.append(initialData['Attributes_Parsed'][i])\n",
    "key_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "initialData.sort_values(by='Category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialData['Category'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialData_group=initialData.groupby('Category',as_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Category1=initialData_group.get_group(1)\n",
    "Category2=initialData_group.get_group(2)\n",
    "Category3=initialData_group.get_group(3)\n",
    "Category4=initialData_group.get_group(4)\n",
    "Category5=initialData_group.get_group(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Category1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyise Each Category\n",
    "\n",
    "category 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Category1.reset_index(drop=True,inplace=True)\n",
    "#Category1.drop(\"index\",axis=1,inplace=True)\n",
    "Category1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_list1=[]\n",
    "for i in range(len(Category1)):\n",
    "    keys_list1.extend(list(Category1['Attributes_Parsed'][i].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys1_count=Counter(keys_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_dict=dict(sorted(keys1_count.items(), key=lambda item: item[1], reverse=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_level_cut={key: keys_dict[key] for key in keys_dict if keys_dict[key]>500}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_level_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractDictValue(dataframe, key):\n",
    "    feature_list=[]\n",
    "    for i in range(len(dataframe)):\n",
    "        if key in dataframe['Attributes_Parsed'][i]:\n",
    "           val=dataframe['Attributes_Parsed'][i][key]\n",
    "           feature_list.append(val)\n",
    "        else:\n",
    "            feature_list.append('None')\n",
    "    \n",
    "    return feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features=pd.DataFrame(Category1[['Index','Primary_Image']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in keys_level_cut:\n",
    "    Features[key]=ExtractDictValue(Category1,key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features['Overall_Features'] = Features[Features.columns[2:65]].apply(lambda x: ','.join(x), axis=1)\n",
    "Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Feature_Dictionary(dataframe, feature, index):\n",
    "    \n",
    "    comp_dict={}\n",
    "    for i in range(len(dataframe)):\n",
    "        key=dataframe[feature][i]\n",
    "        ind=dataframe[index][i]\n",
    "        if key in comp_dict:\n",
    "            comp_dict[key].append(ind)\n",
    "        else:\n",
    "            comp_dict[key]=[ind]\n",
    "    \n",
    "    return comp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureComp_dict=Feature_Dictionary(Features,'Overall_Features','Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "FeatureComp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis Each Category\n",
    " Category 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Category2.reset_index(drop=True,inplace=True)\n",
    "#Category1.drop(\"index\",axis=1,inplace=True)\n",
    "Category2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_list2=[]\n",
    "for i in range(len(Category2)):\n",
    "    keys_list2.extend(list(Category2['Attributes_Parsed'][i].keys()))\n",
    "\n",
    "keys_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys2_count=Counter(keys_list2)\n",
    "keys_dict_2=dict(sorted(keys2_count.items(), key=lambda item: item[1], reverse=True))\n",
    "keys_dict_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_level_cut_2={key: keys_dict_2[key] for key in keys_dict_2 if keys_dict_2[key]>500}\n",
    "keys_level_cut_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features_2=pd.DataFrame(Category2['Index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in keys_level_cut_2:\n",
    "    Features_2[key]=ExtractDictValue(Category2,key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features_2['Overall_Features'] = Features_2[Features_2.columns[1:72]].apply(lambda x: ','.join(x), axis=1)\n",
    "Features_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureComp_dict_2=Feature_Dictionary(Features_2,'Overall_Features','Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureComp_dict_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Each Category\n",
    "\n",
    "category 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Category3.reset_index(drop=True,inplace=True)\n",
    "#Category1.drop(\"index\",axis=1,inplace=True)\n",
    "Category3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_list3=[]\n",
    "for i in range(len(Category3)):\n",
    "    keys_list3.extend(list(Category3['Attributes_Parsed'][i].keys()))\n",
    "\n",
    "keys_list3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "keys3_count=Counter(keys_list3)\n",
    "keys_dict_3=dict(sorted(keys3_count.items(), key=lambda item: item[1], reverse=True))\n",
    "keys_dict_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_level_cut_3={key: keys_dict_3[key] for key in keys_dict_3 if keys_dict_3[key]>100}\n",
    "keys_level_cut_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features_3=pd.DataFrame(Category3['Index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in keys_level_cut_3:\n",
    "    Features_3[key]=ExtractDictValue(Category3,key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features_3['Overall_Features'] = Features_3[Features_3.columns[1:110]].apply(lambda x: ','.join(x), axis=1)\n",
    "Features_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureComp_dict_3=Feature_Dictionary(Features_3,'Overall_Features','Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureComp_dict_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Each Category\n",
    "\n",
    "category 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Category4.reset_index(drop=True,inplace=True)\n",
    "#Category1.drop(\"index\",axis=1,inplace=True)\n",
    "Category4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_list4=[]\n",
    "for i in range(len(Category4)):\n",
    "    keys_list4.extend(list(Category4['Attributes_Parsed'][i].keys()))\n",
    "\n",
    "keys_list4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys4_count=Counter(keys_list4)\n",
    "keys_dict_4=dict(sorted(keys4_count.items(), key=lambda item: item[1], reverse=True))\n",
    "keys_dict_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_level_cut_4={key: keys_dict_4[key] for key in keys_dict_4 if keys_dict_4[key]>=100}\n",
    "keys_level_cut_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features_4=pd.DataFrame(Category4['Index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in keys_level_cut_4:\n",
    "    Features_4[key]=ExtractDictValue(Category4,key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features_4['Overall_Features'] = Features_4[Features_4.columns[1:92]].apply(lambda x: ','.join(x), axis=1)\n",
    "Features_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureComp_dict_4=Feature_Dictionary(Features_4,'Overall_Features','Index')\n",
    "FeatureComp_dict_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Each Category\n",
    "\n",
    "category 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Category5.reset_index(drop=True,inplace=True)\n",
    "#Category1.drop(\"index\",axis=1,inplace=True)\n",
    "Category5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_list5=[]\n",
    "for i in range(len(Category5)):\n",
    "    keys_list5.extend(list(Category5['Attributes_Parsed'][i].keys()))\n",
    "\n",
    "keys_list5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys5_count=Counter(keys_list5)\n",
    "keys_dict_5=dict(sorted(keys5_count.items(), key=lambda item: item[1], reverse=True))\n",
    "keys_dict_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_level_cut_5={key: keys_dict_5[key] for key in keys_dict_5 if keys_dict_5[key]>=100}\n",
    "keys_level_cut_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features_5=pd.DataFrame(Category5['Index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in keys_level_cut_5:\n",
    "    Features_5[key]=ExtractDictValue(Category5,key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features_5['Overall_Features'] = Features_5[Features_5.columns[1:148]].apply(lambda x: ','.join(x), axis=1)\n",
    "Features_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureComp_dict_5=Feature_Dictionary(Features_5,'Overall_Features','Index')\n",
    "FeatureComp_dict_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combine results to create clustering list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "List1=list(FeatureComp_dict.values())\n",
    "List2=list(FeatureComp_dict_2.values())\n",
    "List3=list(FeatureComp_dict_3.values())\n",
    "List4=list(FeatureComp_dict_4.values())\n",
    "List5=list(FeatureComp_dict_5.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Raw_group_list=List1+List2+List3+List4+List5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_label_1=enumerate(List1)\n",
    "product_dict_1={}\n",
    "for i,key in list_label_1:\n",
    "    for x in key:\n",
    "        product_dict_1[x]=1000000+i\n",
    "\n",
    "product_dict_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_label_2=enumerate(List2)\n",
    "product_dict_2={}\n",
    "for i,key in list_label_2:\n",
    "    for x in key:\n",
    "        product_dict_2[x]=2000000+i\n",
    "\n",
    "product_dict_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_label_3=enumerate(List3)\n",
    "product_dict_3={}\n",
    "for i,key in list_label_3:\n",
    "    for x in key:\n",
    "        product_dict_3[x]=3000000+i\n",
    "\n",
    "product_dict_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_label_4=enumerate(List4)\n",
    "product_dict_4={}\n",
    "for i,key in list_label_4:\n",
    "    for x in key:\n",
    "        product_dict_4[x]=4000000+i\n",
    "\n",
    "product_dict_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "list_label_5=enumerate(List5)\n",
    "product_dict_5={}\n",
    "for i,key in list_label_5:\n",
    "    for x in key:\n",
    "        product_dict_5[x]=5000000+i\n",
    "\n",
    "product_dict_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_product_dict={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_product_dict.update(product_dict_1)\n",
    "overall_product_dict.update(product_dict_2)\n",
    "overall_product_dict.update(product_dict_3)\n",
    "overall_product_dict.update(product_dict_4)\n",
    "overall_product_dict.update(product_dict_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "overall_product_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "f = open('result_jan30_2.txt', 'w')\n",
    "\n",
    "#print(\"Index  Group label\", file=f)\n",
    "for keys in overall_product_dict:\n",
    "    print(str(keys)+'\\t'+str(overall_product_dict[keys]), file=f)\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_label=pd.read_csv('mlchallenge_set_validation.csv',sep='\\t',header=None,names=['product_index','true_label'])\n",
    "pred_label=pd.read_csv('result_jan30_2.csv',sep='\\t',header=None,names=['product_index','pred_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_label=pred_label.sort_values('product_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_label.reset_index(drop=True,inplace=True)\n",
    "pred_label.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_label[pred_label['product_index']==194]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison=pd.merge(true_label,pred_label, on='product_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster._supervised import contingency_matrix, check_clusterings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_true=comparison['true_label']\n",
    "labels_pred=comparison['pred_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_true, labels_pred = check_clusterings(labels_true, labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels_true, labels_pred = check_clusterings(labels_true, labels_pred)\n",
    "n_samples = np.int64(labels_true.shape[0])\n",
    "\n",
    "    # Computation using the contingency data\n",
    "contingency = contingency_matrix(labels_true, labels_pred, sparse=True)\n",
    "n_c = np.ravel(contingency.sum(axis=1))\n",
    "n_k = np.ravel(contingency.sum(axis=0))\n",
    "sum_squares = (contingency.data ** 2).sum()\n",
    "C = np.empty((2, 2), dtype=np.int64)\n",
    "C[1, 1] = sum_squares - n_samples\n",
    "C[0, 1] = contingency.dot(n_k).sum() - sum_squares\n",
    "C[1, 0] = contingency.transpose().dot(n_c).sum() - sum_squares\n",
    "C[0, 0] = n_samples ** 2 - C[0, 1] - C[1, 0] - sum_squares\n",
    "    #return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision=1382*1.0/(2856+1382)\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall=1382*1.0/(1382+3972)\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1=2*precision*recall/(precision+recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
